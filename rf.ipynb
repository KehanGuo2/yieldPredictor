{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kguo2/anaconda3/envs/pygeo/lib/python3.9/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.append(root)\n",
    "\n",
    "import random\n",
    "import wandb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from data import rxn\n",
    "import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaxys_mean = 64.05\n",
    "reaxys_median = 68.00\n",
    "reaxys_std = 22.46\n",
    "# preparing data\n",
    "folder = \"./data/datav6_internal\"\n",
    "rxns = rxn(folder)\n",
    "ids = rxns.all_idx2()\n",
    "print(f'Total number of reactions: {len(ids)}')\n",
    "for i, id in enumerate(ids):\n",
    "    fp = rxns.get_fp_fast(id)\n",
    "    aev = rxns.get_aev_fast(id)\n",
    "    qm = rxns.get_qm_fast(id)\n",
    "    steric = rxns.get_steric_desps(id)\n",
    "    mordred = rxns.get_mordred_fast(id)\n",
    "    yld = rxns.get_yield(id)\n",
    "    print(yld)\n",
    "    print(len(fp), len(aev), len(qm), len(steric), len(mordred))\n",
    "    # print(aev)\n",
    "    # print(qm)\n",
    "    # print(steric)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids0 = pickle.load(open(os.path.join(folder, 'normal_ids.pkl'), 'rb'))\n",
    "train_uncertain_ids = pickle.load(open(os.path.join(folder, 'train_uncertain_ids.pkl'),'rb'))\n",
    "# train_ids0 = train_ids0.union(train_uncertain_ids)\n",
    "test_ids = pickle.load(open(os.path.join(folder, 'test_clean_ids.pkl'), 'rb'))\n",
    "test_ids_u = pickle.load(open(os.path.join(folder, 'test_uncertain_ids.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_feature(ids,reaction,standardize=True):\n",
    "    X, Y = [], []\n",
    "    molecule = True\n",
    "    global input_dim\n",
    "    for i,id in enumerate(ids):\n",
    "        context = rxns.get_context_one_hot(id)\n",
    "        fp = rxns.get_fp(id)\n",
    "        # fp = rxns.get_fp_fast(id)\n",
    "        # print(len(fp))\n",
    "        context_fp0 = list(np.array(context + fp)) # 3807\n",
    "        aimnet0 = rxns.get_qm_fast(id)  #51\n",
    "        mordred0 = rxns.get_mordred(id)  #4944\n",
    "        aev0 = rxns.get_aev_fast(id) # 5148\n",
    "        # x = aimnet0 + context_fp0 + mordred0 + aev0 \n",
    "        x = fp\n",
    "        if reaction & molecule:\n",
    "            reaction_x = [x[i + 2048] - x[i] - x[i + 1024] for i in range(1024)]        \n",
    "            \n",
    "            input_dim = len(x)//3*4\n",
    "            combined_x = x + reaction_x\n",
    "            X.append(combined_x)\n",
    "            y = rxns.get_yield(id)\n",
    "            Y.append(y)\n",
    "        elif reaction:\n",
    "            reaction_x = [x[i + 2048] - x[i] - x[i + 1024] for i in range(1024)]        \n",
    "            input_dim = len(x)//3\n",
    "            X.append(reaction_x)\n",
    "            y = rxns.get_yield(id)\n",
    "            Y.append(y)\n",
    "            \n",
    "        else:\n",
    "            X.append(x)\n",
    "            input_dim = len(x)\n",
    "            y = rxns.get_yield(id)\n",
    "            Y.append(y)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = rg.predict(test_X) \n",
    "# make the max item in the item to be 1\n",
    "binary_array = np.zeros_like(yhat)  # Create an yhat of zeros with the same shape\n",
    "binary_array[np.arange(yhat.shape[0]), np.argmax(yhat, axis=1)] = 1\n",
    "\n",
    "print(binary_array)\n",
    "\n",
    "acc = accuracy_score(test_Y, binary_array)\n",
    "f1 = f1_score(test_Y,binary_array, average='weighted')\n",
    "print(f'Accuracy: {acc}, F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "rs, maes, rmses = [], [], []\n",
    "\n",
    "\n",
    "def process_Y(Y):\n",
    "    Y = np.array(Y)\n",
    "    Y = np.clip(Y, 0, 100)\n",
    "    if Y > reaxys_mean + reaxys_std/2:\n",
    "        return [1,0,0]\n",
    "    elif Y < reaxys_mean - reaxys_std/2:\n",
    "        return [0,0,1]\n",
    "    else:\n",
    "        return [0,1,0]\n",
    "    \n",
    "\n",
    "for i in range(5):\n",
    "    reaction = False\n",
    "    train_ids = set(random.sample(list(train_ids0), int(len(train_ids0) * 0.9)))\n",
    "    val_ids = train_ids0 - train_ids\n",
    "    test_u = test_ids_u\n",
    "    # test_u = test_u[int(len(test_u)*0.9):]\n",
    "    train_X, train_Y = get_raw_feature(train_ids, reaction)\n",
    "    test_X, test_Y = get_raw_feature(test_ids, reaction)\n",
    "    train_Y = np.array([process_Y(y) for y in train_Y])\n",
    "    test_Y = np.array([process_Y(y) for y in test_Y])\n",
    "\n",
    "    # preparing model\n",
    "    hyper_parameters = {\n",
    "        'n_estimators': 409,\n",
    "        'max_features': 0.124,\n",
    "        'max_depth': 99\n",
    "    }\n",
    "    # wandb.init(project='yield2', entity='oilab', config=hyper_parameters)\n",
    "    # config = wandb.config\n",
    "    rg = RandomForestRegressor(n_estimators=hyper_parameters['n_estimators'],\n",
    "                            max_features= hyper_parameters['max_features'],\n",
    "                            max_depth=hyper_parameters['max_depth'],\n",
    "                            n_jobs=16, random_state=0)\n",
    "    rg.fit(train_X, train_Y)\n",
    "\n",
    "    # check the performance on the test set\n",
    "    binary_array = np.zeros_like(yhat)  # Create an yhat of zeros with the same shape\n",
    "    binary_array[np.arange(yhat.shape[0]), np.argmax(yhat, axis=1)] = 1\n",
    "\n",
    "    acc = accuracy_score(test_Y, binary_array)\n",
    "    f1 = f1_score(test_Y,binary_array, average='weighted')\n",
    "    print(f'Accuracy: {acc}, F1: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test result on unnormal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs, maes, rmses = [], [], []\n",
    "for i in range(5):\n",
    "    reaction = False\n",
    "    train_ids = set(random.sample(list(train_ids0), int(len(train_ids0) * 0.9)))\n",
    "    val_ids = train_ids0 - train_ids\n",
    "    test_u = test_ids_u\n",
    "    # test_u = test_u[int(len(test_u)*0.9):]\n",
    "    train_X, train_Y = get_raw_feature(train_ids, reaction)\n",
    "    test_X, test_Y = get_raw_feature(test_ids, reaction)\n",
    "    val_X, val_Y = get_raw_feature(val_ids, reaction)\n",
    "    test_X_u, test_Y_u = get_raw_feature(test_u, reaction)\n",
    "    # train_X = rxns.get_fp(list(train_ids))\n",
    "    # train_Y = np.array([rxns.get_yield(idx) for idx in train_ids])\n",
    "    train_Y = (train_Y - reaxys_mean) / reaxys_std\n",
    "    \n",
    "\n",
    "    # val_X = rxns.get_fp(list(val_ids))\n",
    "    # val_Y = np.array([rxns.get_yield(idx) for idx in val_ids])\n",
    "\n",
    "    # test_X = rxns.get_fp(list(test_ids))\n",
    "    # test_Y = np.array([rxns.get_yield(idx) for idx in test_ids])\n",
    "    print(f'Training feature shape: {train_X.shape}')\n",
    "    print(f'Training label shape: {train_Y.shape}')\n",
    "    print(f'Testing feature shape: {test_X_u.shape}')\n",
    "    print(f'Testing label shape: {test_Y_u.shape}')\n",
    "\n",
    "    # preparing model\n",
    "    hyper_parameters = {\n",
    "        'n_estimators': 409,\n",
    "        'max_features': 0.124,\n",
    "        'max_depth': 99\n",
    "    }\n",
    "    # wandb.init(project='yield2', entity='oilab', config=hyper_parameters)\n",
    "    # config = wandb.config\n",
    "    rg = RandomForestRegressor(n_estimators=hyper_parameters['n_estimators'],\n",
    "                            max_features= hyper_parameters['max_features'],\n",
    "                            max_depth=hyper_parameters['max_depth'],\n",
    "                            n_jobs=16, random_state=0)\n",
    "    rg.fit(train_X, train_Y)\n",
    "\n",
    "    # check the performance on the validation set\n",
    "    val_y = rg.predict(val_X) * reaxys_std + reaxys_mean\n",
    "    val_r2 = r2_score(val_Y, val_y)\n",
    "    val_mae = mean_absolute_error(val_Y, val_y)\n",
    "    val_rmse = mean_squared_error(val_Y, val_y, squared=False)\n",
    "    # wandb.log({'val_r2': val_r2, 'val_mae': val_mae, 'val_rmse': val_rmse})\n",
    "    print(f'Val R2: {val_r2:.3f}')\n",
    "    print(f'Val MAE: {val_mae:.3f}')\n",
    "    print(f'Val RMSE: {val_rmse:.3f}')\n",
    "\n",
    "    # check the performance on the test set\n",
    "    yhat = rg.predict(test_X_u) * reaxys_std + reaxys_mean\n",
    "    r2 = r2_score(test_Y_u, yhat)\n",
    "    mae = mean_absolute_error(test_Y_u, yhat)\n",
    "    rmse = mean_squared_error(test_Y_u, yhat, squared=False)\n",
    "\n",
    "    # wandb.log({'r2': r2, 'mae': mae, 'rmse': rmse})\n",
    "    print(f'R2: {r2:.3f}')\n",
    "    print(f'MAE: {mae:.3f}')\n",
    "    print(f'RMSE: {rmse:.3f}')\n",
    "\n",
    "    # # save data ids, model and predictions\n",
    "    # pickle.dump(train_ids, open(os.path.join(params_folder, f'RF/{i}_v2_train_ids.pkl'), 'wb'))\n",
    "    # df_predictions = pd.DataFrame({'id': list(test_ids), 'true': test_Y.tolist(), 'pred': yhat.tolist()})\n",
    "    # df_predictions.to_csv(os.path.join(params_folder, f'RF/{i}_v2_predictions.csv'), index=False)\n",
    "    # pickle.dump(rg, open(os.path.join(params_folder, f'RF/{i}_v2_model.pkl'), 'wb'))\n",
    "\n",
    "    rs.append(r2)\n",
    "    maes.append(mae)\n",
    "    rmses.append(rmse)\n",
    "print(f'R2 mean {np.mean(rs):.3f} std {np.std(rs):.3f}')\n",
    "print(f'MAE mean {np.mean(maes):.3f} std {np.std(maes):.3f}')\n",
    "print(f'RMSE mean {np.mean(rmses):.3f} std {np.std(rmses):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test result on clean set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs, maes, rmses = [], [], []\n",
    "for i in range(5):\n",
    "    reaction = False\n",
    "    train_ids = set(random.sample(list(train_ids0), int(len(train_ids0) * 0.9)))\n",
    "    val_ids = train_ids0 - train_ids\n",
    "    test_u = list(test_ids_u)\n",
    "    test_u = test_u[int(len(test_u)*1):]\n",
    "    train_X, train_Y = get_raw_feature(train_ids, reaction)\n",
    "    test_X, test_Y = get_raw_feature(test_ids, reaction)\n",
    "    val_X, val_Y = get_raw_feature(val_ids, reaction)\n",
    "    test_X_u, test_Y_u = get_raw_feature(test_u, reaction)\n",
    "    # train_X = rxns.get_fp(list(train_ids))\n",
    "    # train_Y = np.array([rxns.get_yield(idx) for idx in train_ids])\n",
    "    train_Y = (train_Y - reaxys_mean) / reaxys_std\n",
    "    \n",
    "\n",
    "    # val_X = rxns.get_fp(list(val_ids))\n",
    "    # val_Y = np.array([rxns.get_yield(idx) for idx in val_ids])\n",
    "\n",
    "    # test_X = rxns.get_fp(list(test_ids))\n",
    "    # test_Y = np.array([rxns.get_yield(idx) for idx in test_ids])\n",
    "    print(f'Training feature shape: {train_X.shape}')\n",
    "    print(f'Training label shape: {train_Y.shape}')\n",
    "    print(f'Testing feature shape: {test_X.shape}')\n",
    "    print(f'Testing label shape: {test_Y.shape}')\n",
    "\n",
    "    # preparing model\n",
    "    hyper_parameters = {\n",
    "        'n_estimators': 409,\n",
    "        'max_features': 0.124,\n",
    "        'max_depth': 99\n",
    "    }\n",
    "    # wandb.init(project='yield2', entity='oilab', config=hyper_parameters)\n",
    "    # config = wandb.config\n",
    "    rg = RandomForestRegressor(n_estimators=hyper_parameters['n_estimators'],\n",
    "                            max_features= hyper_parameters['max_features'],\n",
    "                            max_depth=hyper_parameters['max_depth'],\n",
    "                            n_jobs=16, random_state=0)\n",
    "    rg.fit(train_X, train_Y)\n",
    "\n",
    "    # check the performance on the validation set\n",
    "    val_y = rg.predict(val_X) * reaxys_std + reaxys_mean\n",
    "    val_r2 = r2_score(val_Y, val_y)\n",
    "    val_mae = mean_absolute_error(val_Y, val_y)\n",
    "    val_rmse = mean_squared_error(val_Y, val_y, squared=False)\n",
    "    # wandb.log({'val_r2': val_r2, 'val_mae': val_mae, 'val_rmse': val_rmse})\n",
    "    print(f'Val R2: {val_r2:.3f}')\n",
    "    print(f'Val MAE: {val_mae:.3f}')\n",
    "    print(f'Val RMSE: {val_rmse:.3f}')\n",
    "\n",
    "    # check the performance on the test set\n",
    "    yhat = rg.predict(test_X) * reaxys_std + reaxys_mean\n",
    "    r2 = r2_score(test_Y, yhat)\n",
    "    mae = mean_absolute_error(test_Y, yhat)\n",
    "    rmse = mean_squared_error(test_Y, yhat, squared=False)\n",
    "\n",
    "    # wandb.log({'r2': r2, 'mae': mae, 'rmse': rmse})\n",
    "    print(f'R2: {r2:.3f}')\n",
    "    print(f'MAE: {mae:.3f}')\n",
    "    print(f'RMSE: {rmse:.3f}')\n",
    "\n",
    "    # # save data ids, model and predictions\n",
    "    # pickle.dump(train_ids, open(os.path.join(params_folder, f'RF/{i}_v2_train_ids.pkl'), 'wb'))\n",
    "    # df_predictions = pd.DataFrame({'id': list(test_ids), 'true': test_Y.tolist(), 'pred': yhat.tolist()})\n",
    "    # df_predictions.to_csv(os.path.join(params_folder, f'RF/{i}_v2_predictions.csv'), index=False)\n",
    "    # pickle.dump(rg, open(os.path.join(params_folder, f'RF/{i}_v2_model.pkl'), 'wb'))\n",
    "\n",
    "    rs.append(r2)\n",
    "    maes.append(mae)\n",
    "    rmses.append(rmse)\n",
    "print(f'R2 mean {np.mean(rs):.3f} std {np.std(rs):.3f}')\n",
    "print(f'MAE mean {np.mean(maes):.3f} std {np.std(maes):.3f}')\n",
    "print(f'RMSE mean {np.mean(rmses):.3f} std {np.std(rmses):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
